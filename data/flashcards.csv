Какую основную задачу решает модель на этапе предобучения (pre-training)?,Предсказание следующего токена в последовательности текста.
"Гипотеза «Большого комка вычислений» (Big Blob of Compute Hypothesis) утверждает, что _____.",Универсальный интеллект возникает при подаче огромного объема данных и вычислительных мощностей в общую архитектуру.
В чем заключается основное отличие Mixture of Experts (MoE) от плотных (dense) моделей?,"В MoE для обработки каждого токена активируется только подмножество параметров («экспертов»), а не вся сеть."
Термин: Роутер (Router) в архитектуре MoE.,"Определение: Компонент, выбирающий наиболее подходящих «экспертов» для обработки конкретного входного токена."
"Как называются модели, веса которых доступны для скачивания и локального запуска?",Модели с открытыми весами (Open-weight models).
Какова главная цель этапа промежуточного обучения (mid-training)?,"Специализация модели, например, на длинном контексте или специфических типах данных после основного предобучения."
Что такое «катастрофическое забывание» (catastrophic forgetting) в контексте нейросетей?,Потеря моделью ранее усвоенных знаний или навыков при обучении на новых данных.
Термин: RLHF.,Определение: Обучение с подкреплением на основе отзывов людей для настройки стиля и полезности ответов.
Какую роль в постобучении играет SFT (Supervised Fine-Tuning)?,Обучение модели имитировать высококачественные диалоги или следовать инструкциям на основе экспертных примеров.
В чем особенность метода RLVR (Reinforcement Learning with Verifiable Rewards)?,"Модель получает вознаграждение на основе объективно проверяемых результатов, таких как правильный ответ в математике или рабочий код."
Каким образом синтетические данные помогают в предобучении моделей?,Они позволяют перефразировать или структурировать существующую информацию для повышения её качества и усвояемости моделью.
Что описывают «законы масштабирования» (Scaling Laws) в ИИ?,"Математическую зависимость качества модели от объема вычислительной мощности, данных и количества параметров."
Процесс: Дистилляция (Distillation).,Передача знаний от крупной «учительской» модели более компактной «студенческой» модели для ускорения её работы.
Как масштабирование во время вывода (inference-time scaling) влияет на ответы модели?,Оно позволяет модели тратить больше времени и токенов на «размышления» перед выдачей окончательного ответа.
Термин: KV Cache.,Определение: Механизм хранения промежуточных состояний внимания для ускорения генерации последующих токенов.
"Для чего используются форматы квантования, такие как FP8 или FP4?","Для уменьшения объема памяти, занимаемой весами модели, и ускорения вычислений за счет снижения точности чисел."
В чем заключается «Горький урок» (The Bitter Lesson) Ричарда Саттона?,"Общие методы, использующие масштабируемые вычисления, в долгосрочной перспективе всегда побеждают подходы, основанные на специфических человеческих знаниях."
Какую функцию выполняет механизм внимания (Attention) в трансформере?,Определяет степень важности каждого слова в контексте относительно других слов при обработке последовательности.
Что подразумевается под «разреженностью» (sparsity) в Mixture of Experts?,Использование лишь малой части вычислительных ресурсов модели для обработки каждого отдельного входного сигнала.
Термин: Авторегрессионная модель.,"Определение: Модель, генерирующая текст последовательно, где каждый новый токен зависит от всех предыдущих."
Как метод DPO (Direct Preference Optimization) упрощает обучение моделей?,Он позволяет настраивать предпочтения модели напрямую без необходимости обучения отдельной модели вознаграждения.
В чем преимущество использования группового внимания (Group Query Attention)?,"Оно сокращает размер KV-кеша, позволяя обрабатывать более длинный контекст при меньших затратах памяти."
Что такое «галлюцинации» ИИ-модели?,"Генерация фактологически неверной или бессмысленной информации, представленной как истина."
Концепция: Chain of Thought (Цепочка рассуждений).,"Метод, при котором модель описывает промежуточные шаги решения задачи перед выдачей итогового ответа."
Как обучение на «цепочках рассуждений» влияет на вычислительную сложность вывода?,"Оно увеличивает время генерации и стоимость ответа, так как модель создает большее количество промежуточных токенов."
Что такое «загрязнение данных» (data contamination) в оценке моделей?,"Ситуация, когда тестовые задания попадают в обучающую выборку, что приводит к искусственному завышению результатов тестов."
Как изменяется эффективность RLVR по мере усложнения задач?,"Эффективность растет, так как модель может обучаться методом проб и ошибок в областях с четкими критериями успеха."
Термин: Context Window (Окно контекста).,"Определение: Максимальный объем текста, который модель может учитывать одновременно при генерации ответа."
В чем заключается разница между субъективными и объективными вознаграждениями в постобучении?,"Субъективные основаны на вкусах людей (RLHF), объективные — на проверяемых фактах или правилах (RLVR)."
Процесс: Использование инструментов (Tool Use/Function Calling).,"Способность модели вызывать внешние программы, такие как калькулятор или поиск, для решения задач, недоступных чистому тексту."
Что такое «обучение в контексте» (In-context learning)?,"Способность модели адаптироваться к новым задачам на основе примеров, предоставленных непосредственно в запросе пользователя."
Для чего в обучении моделей используется Common Crawl?,Как гигантский источник нефильтрованного текста из открытого интернета для этапа предобучения.
В чем состоит риск использования исключительно синтетических данных для обучения?,"Модель может начать деградировать, усиливая собственные ошибки и теряя связь с реальным человеческим языком."
Термин: Контекстное затухание (Context degradation).,"Определение: Снижение точности модели при работе с очень длинными текстами, даже если они формально входят в окно контекста."
Что такое «ага-момент» (aha moment) в обучении модели DeepSeek R1?,"Момент, когда модель в процессе рассуждения сама обнаружила ошибку и начала исправлять свой подход."
Как метод «Reinforcement Learning from AI Feedback» (RLAIF) отличается от традиционного RLHF?,"Вместо людей для оценки ответов и формирования предпочтений используется другая, более мощная языковая модель."
Концепция: Конституциональный ИИ (Constitutional AI).,Метод обучения модели следовать набору этических принципов или правил без прямого вмешательства человека в каждый пример.
Что означает термин «9/9/6» в контексте культуры разработки ИИ?,"График работы с 9 утра до 9 вечера 6 дней в неделю, характерный для многих ведущих лабораторий."
В чем основное ограничение диффузионных моделей текста по сравнению с авторегрессионными?,Сложность интеграции инструментов и пошагового рассуждения из-за параллельной природы генерации токенов.
Термин: Токен (Token).,"Определение: Базовая единица текста (слово, часть слова или символ), которой оперирует языковая модель."
Каким образом «закон Амдала» ограничивает прогресс ИИ-агентов?,"Общая скорость системы ограничена самым медленным этапом, например, временем ожидания ответа от интерфейса или человека."
Что такое «непрерывное обучение» (Continual Learning)?,Способность модели постоянно обновлять свои знания в процессе эксплуатации без полной перетренировки.
Почему масштабирование RLHF имеет предел насыщения по сравнению с RLVR?,"Человеческие предпочтения ограничены стилем и форматированием, в то время как сложность математических задач почти бесконечна."
Процесс: Аблиационные исследования (Ablation studies).,Метод оценки вклада отдельных компонентов модели путем их поочередного удаления или изменения.
Как «латентное внимание» (Multi-head Latent Attention) помогает оптимизировать инференс?,"Оно значительно сжимает размер KV-кеша, сохраняя при этом выразительную мощность модели."
Что такое «бенчмарк» (Benchmark) в контексте ИИ?,"Стандартизированный набор задач для сравнения производительности различных моделей (например, MMLU или MATH)."
В чем заключается идея «агентов» (AI Agents)?,Использование языковых моделей для автономного выполнения последовательности действий в цифровой или физической среде.
Термин: Переобучение (Overfitting).,"Определение: Состояние, при котором модель слишком хорошо запоминает тренировочные данные, но плохо работает на новых примерах."
Как «инференс-стек» (Inference stack) влияет на доступность ИИ?,"Оптимизация программного обеспечения (например, vLLM) позволяет запускать более мощные модели на менее дорогом оборудовании."
Что такое «режим размышления» (Thinking mode) в новых моделях вроде o1?,"Скрытый процесс генерации промежуточных рассуждений, который происходит до того, как пользователь увидит итоговый ответ."
Для чего нужно «уравнивание» (Alignment) моделей ИИ?,"Чтобы гарантировать, что поведение и цели модели соответствуют человеческим ценностям и инструкциям пользователя."
В чем разница между энкодером (Encoder) и декодером (Decoder) в архитектуре Трансформер?,"Энкодер обрабатывает входную последовательность целиком, а декодер генерирует выходную последовательность по одному токену."
Концепция: Обучение с нулевым примером (Zero-shot learning).,"Способность модели выполнить задачу, которую она никогда не видела в процессе обучения, только по описанию."
Что такое «температура» (Temperature) при генерации текста?,"Параметр, регулирующий степень случайности и креативности в ответах модели."
Процесс: Токенизация (Tokenization).,"Преобразование сырого текста в числовые идентификаторы (токены), понятные нейронной сети."
Как использование FP8 влияет на пропускную способность (throughput) обучения?,"Оно позволяет передавать больше данных через память и выполнять больше операций в секунду, ускоряя обучение в разы."
Что такое «преимущество первого хода» (First-mover advantage) в индустрии ИИ?,"Преимущество компаний, первыми захвативших рынок и привычки пользователей (например, OpenAI с ChatGPT)."
Термин: Оценка ИИ как судьи (LLM-as-a-judge).,"Определение: Метод оценки качества ответов одной модели с помощью другой, более мощной языковой модели."
Как «скользящее окно внимания» (Sliding window attention) помогает экономить ресурсы?,"Модель ограничивает область внимания только ближайшими токенами, что снижает вычислительную сложность для длинных текстов."
В чем заключается сложность создания «суперумного программиста» на базе ИИ?,В нехватке качественных данных о сложных распределенных системах и необходимости понимания огромных кодовых баз.
Что такое «параллелизм данных» (Data parallelism) при обучении?,"Метод распределения разных порций данных между множеством GPU, которые обучают идентичные копии модели."
Термин: Эмбеддинг (Embedding).,"Определение: Векторное представление токена в многомерном пространстве, отражающее его смысловое значение."
Что описывает «уровень логитов» (Logits layer)?,"Последний слой сети, который выдает сырые вероятности для каждого возможного следующего токена в словаре."
Зачем в процессе предобучения используется «перемешивание» (shuffling) данных?,"Чтобы модель не выучивала случайные закономерности, связанные с порядком документов в наборе данных."
В чем риск «чрезмерной оптимизации» (Over-optimization) в RLHF?,"Модель может научиться отвечать так, чтобы нравиться судьям, при этом теряя фактическую точность или становясь слишком многословной."
Концепция: Социальный выбор (Social choice theory) в RLHF.,Метод агрегации противоречивых предпочтений разных людей для создания сбалансированной модели вознаграждения.
Что такое «проверка на иголку в стоге сена» (Needle-in-a-haystack test)?,"Проверка способности модели находить конкретный факт, глубоко спрятанный в очень длинном тексте."
Как «функция ценности» (Value function) помогает в поиске решений?,"Она предсказывает вероятность успеха для текущего промежуточного шага, помогая модели выбирать лучший путь рассуждения."
Что такое «открытый исходный код» (Open Source) в применении к ИИ?,"Обычно это маркетинговый термин, означающий открытость весов, но не всегда — данных или кода обучения."
Процесс: Отсев данных (Data pruning).,"Удаление низкокачественных, повторяющихся или вредных документов из обучающей выборки для повышения эффективности обучения."
Как изменяется стоимость обслуживания модели по сравнению со стоимостью её обучения?,Стоимость обслуживания (inference) при массовом использовании может в разы превышать разовые затраты на обучение.
Термин: Гравитационное притяжение данных (Data gravity).,"Определение: Сложность перемещения огромных наборов данных, что вынуждает размещать вычислительные мощности рядом с хранилищем."
Что такое «параллелизм тензоров» (Tensor parallelism)?,Разделение весов одного слоя нейронной сети между несколькими GPU для обработки очень больших моделей.
Зачем моделям вроде Claude или GPT нужна «память» (Memory feature)?,Чтобы сохранять контекст и предпочтения пользователя между разными сессиями диалога.
Какую роль играет RMSNorm в современных трансформерах?,Это более быстрый и стабильный способ нормализации активаций нейронов по сравнению с классическим LayerNorm.
В чем заключается «ошибка выжившего» при оценке моделей по бенчмаркам?,"Мы видим только те задачи, на которых модель тестировали, и не знаем о её пробелах в других, не протестированных областях."
Что означает «зазубренный профиль способностей» (jagged frontier of capabilities)?,"Ситуация, когда модель демонстрирует сверхчеловеческие навыки в одних задачах и проваливается в элементарных других."
Термин: Выборочное предсказание (Top-p sampling).,"Определение: Метод выбора следующего слова, при котором рассматриваются только самые вероятные варианты, сумма которых достигает порога $p$."
Как «эффект масштаба» влияет на геополитическую конкуренцию в области ИИ?,Только страны и компании с доступом к огромному капиталу и электроэнергии могут создавать модели передового уровня.
Что такое «ложные отрицательные результаты» в тестах ИИ?,"Случаи, когда модель знает правильный ответ, но не дает его из-за неудачной формулировки вопроса или настроек безопасности."