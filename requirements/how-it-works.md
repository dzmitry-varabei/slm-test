# Как работает AI-Trainer: SLM, LLM и Feedback Loop

## Для кого эта статья

Для студентов, которые хотят понять, как устроено приложение AI-Trainer изнутри: почему мы используем две модели, как работает промпт-инженерия, и как система улучшается через обратную связь преподавателя.

---

## Часть 1. Проблема: кто проверяет проверяющего?

Представьте: вы учите ИИ-ассистента проверять ответы студентов. Вы даёте ему вопрос, эталонный ответ и ответ студента. Он должен сказать — верно, частично верно или неверно.

**Проблема:** малые модели (SLM, ~8 млрд параметров) — быстрые и дешёвые, но часто ошибаются:
- Придираются к формулировкам, хотя смысл верный
- Пропускают фактические ошибки
- Не понимают, что один и тот же ответ можно сформулировать по-разному

**Решение в AI-Trainer:**
1. SLM проверяет ответ (быстро, ~300-500мс)
2. Claude перепроверяет SLM (медленнее, ~3-10с, но точнее)
3. Преподаватель корректирует, если обе модели ошибаются
4. Коррекция улучшает будущие проверки SLM

---

## Часть 2. Как SLM оценивает ответ

### Промпт-инженерия

SLM не «понимает» задачу сама — ей нужен чёткий промпт. Вот что мы отправляем:

**System prompt** (инструкция для модели):
```
Ты — ассистент-стажёр экзаменатора. Сравни ответ студента с эталонным.

ПРАВИЛА:
1. Оценивай СМЫСЛ, не точное совпадение слов
2. Не требуй всех деталей эталона — достаточно ключевой идеи
3. Допускай ответы на русском и английском
4. Если указано несколько допустимых ответов — достаточно совпадения с любым

ШКАЛА:
- "correct" — ключевая идея верна
- "partially_correct" — частично прав, но упустил важное
- "incorrect" — неверно или не по теме

ФОРМАТ (строго JSON):
{"verdict": "...", "comment": "Краткий комментарий"}
```

**User prompt** (конкретная задача):
```
ВОПРОС: Что такое бенчмарк в контексте ИИ?

ЭТАЛОННЫЙ ОТВЕТ: Стандартизированный набор задач для сравнения
производительности моделей (например, MMLU или MATH).

ОТВЕТ СТУДЕНТА: Бенчмарк - это стандартный тест для оценки моделей ИИ
```

### Что важно в промпте

| Элемент | Зачем |
|---------|-------|
| Роль ("стажёр экзаменатора") | Задаёт контекст и уровень строгости |
| Правила | Предотвращают типичные ошибки SLM |
| Шкала с определениями | Единообразная оценка |
| Формат JSON | Парсинг ответа без ошибок |

### Парсинг ответа

SLM возвращает текст. Мы пытаемся извлечь JSON тремя способами:
1. Прямой `JSON.parse()` — если модель послушалась
2. Извлечение из markdown-блока ` ```json ... ``` ` — частая привычка моделей
3. Regex-фоллбек — ищем `"verdict": "correct"` в тексте

---

## Часть 3. Зачем нужен Claude (LLM-as-a-Judge)

Claude — это большая модель (~10x параметров SLM). Она:
- Лучше понимает нюансы смысла
- Может объяснить свою оценку подробно
- Реже ошибается на пограничных случаях

### Как вызывается Claude

Мы используем **Claude CLI** — консольный инструмент, который не требует API-ключа:

```
echo "промпт" | claude --output-format text --max-turns 1
```

Запускается как дочерний процесс (child_process.spawn), промпт передаётся через stdin.

### Различия в промпте

| | SLM | Claude |
|--|-----|--------|
| Роль | "стажёр экзаменатора" | "опытный экзаменатор" |
| Строгость | Мягче | Строже к фактическим ошибкам |
| Формат ответа | verdict + comment | verdict + comment + **explanation** |
| Скорость | 300-500мс | 3-10с |

### Когда запускается Claude

Только в **Debug Mode** — параллельно с SLM. Если Claude упал (таймаут, ошибка CLI), SLM-оценка всё равно возвращается.

```
                    ┌─── SLM (Groq) ──→ verdict + comment
POST /evaluate ─────┤
  (debug=true)      └─── Claude CLI ──→ verdict + comment + explanation
```

---

## Часть 4. Несколько правильных ответов

На многие вопросы можно ответить по-разному. Например:

> **Вопрос:** Что такое AGI?

> **Ответ 1:** Искусственный общий интеллект — ИИ, способный решать любые интеллектуальные задачи на уровне человека

> **Ответ 2:** AGI — это гипотетическая система ИИ, которая может обучаться и применять знания в любой области

Оба ответа верны. В AI-Trainer:
- Основной эталон хранится в таблице `flashcards`
- Альтернативные ответы — в `flashcard_answers`
- При оценке SLM и Claude получают **все** допустимые ответы

В промпте это выглядит так:
```
ДОПУСТИМЫЕ ЭТАЛОННЫЕ ОТВЕТЫ:
  1. Искусственный общий интеллект — ИИ, способный решать...
  2. AGI — это гипотетическая система ИИ, которая может...
```

---

## Часть 5. Feedback Loop — как SLM учится

### Проблема

SLM ошибается. Иногда ставит «partially_correct» ответу, который на самом деле correct. Переобучение модели — дорого и долго. Нам нужен способ быстрой коррекции.

### Решение: Few-Shot Learning через промпт

**Few-shot learning** — техника, при которой модели показывают несколько примеров правильного поведения прямо в промпте, без изменения весов модели.

#### Как это работает в AI-Trainer

1. Преподаватель видит, что SLM сказала `partially_correct`, а на самом деле ответ `correct`
2. Нажимает кнопку **"Correct"** в Teacher Override
3. Система создаёт запись в `prompt_examples`:

```json
{
  "question": "Что такое бенчмарк?",
  "reference_answer": "Стандартизированный набор задач...",
  "user_answer": "Бенчмарк - это стандартный тест...",
  "expected_verdict": "correct",
  "reason": "SLM said partially_correct, teacher corrected to correct"
}
```

4. При следующей оценке system prompt дополняется:

```
ПРИМЕРЫ ПРАВИЛЬНОЙ ОЦЕНКИ (учись на них):

ПРИМЕР 1:
Вопрос: Что такое бенчмарк?
Эталонный ответ: Стандартизированный набор задач...
Ответ студента: Бенчмарк - это стандартный тест...
Верный вердикт: correct, потому что SLM said "partially_correct",
teacher corrected to "correct"
```

### Ограничения few-shot подхода

| Плюсы | Минусы |
|-------|--------|
| Мгновенный эффект, без переобучения | Не гарантирует результат |
| Дешёво — только текст в промпте | Занимает место в контексте |
| Понятно преподавателю | Лимит: ~10 примеров |
| Работает с любой моделью | Модель может проигнорировать |

### Почему лимит в 10 примеров

Малые модели имеют ограниченное **контекстное окно** (8K-32K токенов). Каждый few-shot пример — это ~100-200 токенов. При 10 примерах это ~1-2K токенов, что оставляет достаточно места для основной задачи. Если примеров станет 50+ — промпт раздуется, и качество ответа SLM упадёт.

---

## Часть 6. Debug Mode — прозрачность

Debug Mode — это «рентген» для процесса оценки. Преподаватель видит:

### 1. Полный промпт SLM
Весь текст, который получила модель: system prompt + few-shot примеры + вопрос + ответы. Это позволяет понять, **почему** модель ответила именно так.

### 2. Raw ответ SLM
Неформатированный текст от модели — до парсинга. Полезно, если парсер неправильно извлёк verdict.

### 3. Счётчик токенов
`prompt_tokens` — сколько токенов занял промпт. `completion_tokens` — сколько сгенерировала модель. Помогает следить за тем, не перегружен ли контекст.

### 4. Оценка Claude
Вердикт + подробное объяснение. Claude анализирует ответ глубже и может заметить то, что SLM пропустила.

### 5. Эталонный ответ
Все допустимые варианты ответа — чтобы преподаватель мог сравнить.

### 6. Teacher Override
Три кнопки: Correct / Partial / Incorrect. Одно нажатие — и коррекция сохранена.

---

## Часть 7. Архитектура одним взглядом

```
Студент                Преподаватель
   │                        │
   │ ответ                  │ debug mode + override
   ▼                        ▼
┌──────────────────────────────────┐
│            React UI              │
│  Student Mode  │  Debug Mode     │
└────────────────┬─────────────────┘
                 │ HTTP
┌────────────────┴─────────────────┐
│          Express Server          │
│                                  │
│  ┌──────────┐  ┌──────────────┐  │
│  │   SLM    │  │ Claude CLI   │  │
│  │  (Groq)  │  │ (арбитр)    │  │
│  │ 300-500ms│  │ 3-10s       │  │
│  └────┬─────┘  └──────┬──────┘  │
│       │               │         │
│       ▼               ▼         │
│  ┌──────────────────────────┐   │
│  │  SQLite                  │   │
│  │  interactions            │   │
│  │  prompt_examples ◄───────┼── │── teacher override
│  │  flashcards + answers    │   │     → few-shot example
│  └──────────────────────────┘   │
└──────────────────────────────────┘
```

---

## Ключевые концепции для запоминания

1. **SLM (Small Language Model)** — малая модель (~8B параметров), быстрая, но неточная
2. **LLM-as-a-Judge** — большая модель (Claude) проверяет работу малой
3. **Prompt Engineering** — управление поведением модели через текстовые инструкции
4. **Few-Shot Learning** — обучение на примерах прямо в промпте, без изменения весов
5. **Feedback Loop** — цикл: ошибка SLM → коррекция преподавателя → пример в промпте → улучшение
6. **Context Window** — ограниченный объём текста, который модель может обработать за раз
7. **Token** — единица текста для модели (~0.75 слова для русского языка)
